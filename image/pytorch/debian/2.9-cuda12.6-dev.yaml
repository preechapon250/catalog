# syntax=dhi.io/build:1-debian13

name: PyTorch 2.9.x (dev)
image: dhi.io/pytorch
variant: dev
tags:
  - 2.9-cuda12.6-cudnn9-dev
  - 2.9.1-cuda12.6-cudnn9-dev
  - 2.9-cuda12.6-cudnn9-debian13-dev
  - 2.9.1-cuda12.6-cudnn9-debian13-dev
platforms:
  - linux/amd64
  - linux/arm64
vars:
  BINUTILS_REFERENCE: dhi/pkg-binutils:2.45-debian13@sha256:48107c1824276349ccbddce3853299de8b7c6a554b775957864d44c7b9a6b5b4
  COMMIT_SHA: d38164a545b4a4e4e0cf73ce67173f70574890b6
  CUDA_MAJOR_MINOR_VERSION: "12.6"
  CUDA_MAJOR_VERSION: "12"
  CUDA_MINOR_VERSION: "6"
  CUDA_PATH: cu126
  CUDA_REFERENCE: nvidia/cuda:12.6.3-cudnn-devel-ubuntu22.04@sha256:b3e7fba84d169f46939f00c25be7d016f712a8d651f4756d6a55e693d84d94f2
  CUDNN_VERSION: "9"
  DEBIAN_VERSION: "13"
  LIBPNG_REFERENCE: dhi/pkg-libpng:1.6.53-debian13@sha256:c22c905dde05f2a17dbb51bb3678c1c0acfd8af8ded25db0419f47e2359c70e7
  PIP_CMAKE_VERSION: 4.1.2
  PIP_IPYTHON_VERSION: 9.6.0
  PIP_NUMPY_VERSION: 2.3.4
  PIP_PYYAML_VERSION: 6.0.3
  PYTHON_DEV_REFERENCE: dhi/python:3.11.14-debian13-dev@sha256:26d347ab41bf525ead393378d476376a4b0ff74c8617faa92d71e1c72799a102
  PYTHON_REFERENCE: dhi/python:3.11.14-debian13@sha256:04a0800899b60ef39a724eddbf105f2985e575fc1663644450efc1cc86f0eca3
  PYTORCH_CUDA_VERSION: 12.6.3
  PYTORCH_CUDNN_VERSION: 9.10.2.21
  PYTORCH_PYTHON_VERSION: "3.11"
  TAG_CUDA_VERSION: "12.6"
  TAG_CUDNN_VERSION: "9"
  TAG_TORCH_VERSION: "2.9"
  TORCHAUDIO_VERSION: 2.9.1
  TORCHVISION_VERSION: 0.24.1
  TRACKED_CUDA_VERSION: "12.6"
  VERSION: 2.9.1
contents:
  packages:
    - '!gawk'
    - '!libelogind0'
    - '!mawk'
    - '!original-awk'
    - apt
    - base-files
    - build-essential
    - ca-certificates
    - diffutils
    - dpkg
    - grep
    - libc-bin
    - mawk
    - perl-base
    - sed
    - util-linux
    - zlib1g-dev
  builds:
    - name: pytorch build
      uses: dhi.io/python:3.11.14-debian13-dev@sha256:26d347ab41bf525ead393378d476376a4b0ff74c8617faa92d71e1c72799a102
      environment:
        CUDA_PATH: cu126
        INDEX_ARGS: --index-url https://download.pytorch.org/whl/cu126/
        INSTALL_CHANNEL: whl
        PATH: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/bin:/bin:/opt/python/bin
      contents:
        packages:
          - base-files
          - build-essential
          - ca-certificates
          - ccache
          - cmake
          - ninja-build
          - coreutils
          - curl
          - bash
          - grep
          - libc-bin
          - sed
          - libjpeg-dev
        files:
          - url: git+https://github.com/pytorch/pytorch.git#v2.9.1
            checksum: d38164a545b4a4e4e0cf73ce67173f70574890b6
            path: ${source.dir}/pytorch-src
            uid: 0
            gid: 0
        artifacts:
          - name: nvidia/cuda:12.6.3-cudnn-devel-ubuntu22.04@sha256:b3e7fba84d169f46939f00c25be7d016f712a8d651f4756d6a55e693d84d94f2
            includes:
              - usr/local/cuda-*
            uid: 0
            gid: 0
      pipeline:
        - name: create cuda symlinks
          work-dir: /usr/local
          runs: |
            set -eux -o pipefail

            # Create standard symlinks for the build process.
            [ -d /usr/local/cuda-12.6 ]
            ln -sf cuda-12.6 /usr/local/cuda-12
            ln -sf cuda-12 /usr/local/cuda
        - name: run ccache (logic from dev-base build in upstream)
          work-dir: ${source.dir}/pytorch-src
          runs: |
            set -eux -o pipefail

            /usr/sbin/update-ccache-symlinks
            mkdir -p /opt/ccache
            ccache --set-config=cache_dir=/opt/ccache
        - name: install runtime requirements
          work-dir: ${source.dir}/pytorch-src
          privileged: true
          runs: |
            set -eux -o pipefail

            pip install PyYAML==6.0.3 numpy==2.3.4 ipython==9.6.0 cmake==4.1.2
            pip install -r requirements.txt
        - name: install OpenAI triton from binary captured by the pytorch dev team
          work-dir: ${source.dir}/pytorch-src
          privileged: true
          runs: |
            set -eux -o pipefail

            make triton
        - name: install primary torch package
          work-dir: ${source.dir}
          privileged: true
          runs: |
            set -eux -o pipefail

            pip install $INDEX_ARGS torch==2.9.1
            python3 -c 'import torch'
        - name: verify pytorch base package and GPU integration
          runs: |
            set -eux -o pipefail

            IS_CUDA=$(python3 -c 'import torch; print(torch.cuda._is_compiled())')
            if [ "${IS_CUDA}" != "True" ]; then
              echo "ERROR: CUDA support not found in PyTorch installation for ${ARCH}!"
              exit 1
            fi
        - name: install torchvision, torchaudio matching versions in upstream
          work-dir: ${source.dir}
          privileged: true
          runs: |
            set -eux -o pipefail

            pip install $INDEX_ARGS \
              torch==2.9.1 \
              torchvision==0.24.1 \
              torchaudio==2.9.1

            python3 -c "import torchvision"
            python3 -c "import torchaudio"
      outputs:
        - source: /opt
          target: /opt
          uid: 0
          gid: 0
          diff: true
  artifacts:
    - name: dhi.io/python:3.11.14-debian13-dev@sha256:26d347ab41bf525ead393378d476376a4b0ff74c8617faa92d71e1c72799a102
      includes:
        - opt/**
        - usr/**
      uid: 0
      gid: 0
    - name: nvidia/cuda:12.6.3-cudnn-devel-ubuntu22.04@sha256:b3e7fba84d169f46939f00c25be7d016f712a8d651f4756d6a55e693d84d94f2
      includes:
        - NGC-DL-CONTAINER-LICENSE
        - usr/local/cuda-12.6
      uid: 0
      gid: 0
accounts:
  root: true
  run-as: root
  users:
    - name: nonroot
      uid: 65532
      gid: 65532
    - name: _apt
      uid: 42
      gid: 65532
  groups:
    - name: nonroot
      gid: 65532
      members:
        - nonroot
os-release:
  name: Docker Hardened Images (Debian)
  id: debian
  version-id: "13"
  version-codename: trixie
  pretty-name: Docker Hardened Images/Debian GNU/Linux 13 (trixie)
  home-url: https://docker.com/products/hardened-images/
  bug-report-url: https://docker.com/support/
environment:
  CUDA_VERSION: 12.6.3
  DEBIAN_FRONTEND: noninteractive
  LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
  LIBRARY_PATH: /usr/local/cuda/lib64/stubs
  NVARCH: ${target.arch}
  NVIDIA_CTK_LIBCUDA_DIR: /usr/lib/${target.arch}-linux-gnu
  NVIDIA_DRIVER_CAPABILITIES: compute,utility
  NVIDIA_PRODUCT_NAME: CUDA
  NVIDIA_REQUIRE_CUDA: cuda>=12.6 brand=unknown,driver>=470,driver<471 brand=grid,driver>=470,driver<471 brand=tesla,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=vapps,driver>=470,driver<471 brand=vpc,driver>=470,driver<471 brand=vcs,driver>=470,driver<471 brand=vws,driver>=470,driver<471 brand=cloudgaming,driver>=470,driver<471 brand=unknown,driver>=535,driver<536 brand=grid,driver>=535,driver<536 brand=tesla,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=vapps,driver>=535,driver<536 brand=vpc,driver>=535,driver<536 brand=vcs,driver>=535,driver<536 brand=vws,driver>=535,driver<536 brand=cloudgaming,driver>=535,driver<536 brand=unknown,driver>=550,driver<551 brand=grid,driver>=550,driver<551 brand=tesla,driver>=550,driver<551 brand=nvidia,driver>=550,driver<551 brand=quadro,driver>=550,driver<551 brand=quadrortx,driver>=550,driver<551 brand=nvidiartx,driver>=550,driver<551 brand=vapps,driver>=550,driver<551 brand=vpc,driver>=550,driver<551 brand=vcs,driver>=550,driver<551 brand=vws,driver>=550,driver<551 brand=cloudgaming,driver>=550,driver<551 brand=unknown,driver>=560,driver<561 brand=grid,driver>=560,driver<561 brand=tesla,driver>=560,driver<561 brand=nvidia,driver>=560,driver<561 brand=quadro,driver>=560,driver<561 brand=quadrortx,driver>=560,driver<561 brand=nvidiartx,driver>=560,driver<561 brand=vapps,driver>=560,driver<561 brand=vpc,driver>=560,driver<561 brand=vcs,driver>=560,driver<561 brand=vws,driver>=560,driver<561 brand=cloudgaming,driver>=560,driver<561 brand=unknown,driver>=565,driver<566 brand=grid,driver>=565,driver<566 brand=tesla,driver>=565,driver<566 brand=nvidia,driver>=565,driver<566 brand=quadro,driver>=565,driver<566 brand=quadrortx,driver>=565,driver<566 brand=nvidiartx,driver>=565,driver<566 brand=vapps,driver>=565,driver<566 brand=vpc,driver>=565,driver<566 brand=vcs,driver>=565,driver<566 brand=vws,driver>=565,driver<566 brand=cloudgaming,driver>=565,driver<566
  NVIDIA_VISIBLE_DEVICES: all
  PATH: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/bin:/bin:/opt/python/bin
  PYTORCH_VERSION: $VERSION
paths:
  - type: directory
    path: /workspace
    uid: 65532
    gid: 65532
    mode: "0755"
  - type: directory
    path: /usr/local
    uid: 0
    gid: 0
    mode: "0755"
  - type: symlink
    path: /usr/local/cuda-12
    uid: 0
    gid: 0
    source: /usr/local/cuda-12.6
  - type: symlink
    path: /usr/local/cuda
    uid: 0
    gid: 0
    source: /usr/local/cuda-12.6
annotations:
  com.nvidia.volumes.needed: nvidia_driver
  org.opencontainers.image.description: PyTorch - Deep learning framework with GPU acceleration
  org.opencontainers.image.licenses: BSD-3-Clause
cmd:
  - /bin/bash
tests:
  - name: Run PyTorch tests
    directory: image/pytorch/tests
    commands:
      - go test . -count=1 -v
    exit-code: 0
  - name: Run testcontainers basic tests
    directory: test/go-testing/base
    commands:
      - go test . -count=1 -v
    exit-code: 0
  - name: Run APT package manager tests
    directory: test/go-testing/package_manager
    commands:
      - go test . -count=1 -v
    exit-code: 0
