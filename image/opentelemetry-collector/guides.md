## Prerequisites

All examples in this guide use the public image. If you’ve mirrored the repository for your own use (for example, to
your Docker Hub namespace), update your commands to reference the mirrored image instead of the public one.

For example:

- Public image: `dhi.io/<repository>:<tag>`
- Mirrored image: `<your-namespace>/dhi-<repository>:<tag>`

For the examples, you must first use `docker login dhi.io` to authenticate to the registry to pull the images.

## What's included in this opentelemetry-collector image

This Docker Hardened opentelemetry-collector image includes:

- The otelcol (OpenTelemetry Collector) binary built from the official opentelemetry-collector-releases distributions.
- A default configuration installed at /etc/otelcol/config.yaml (core) or /etc/otelcol-contrib/config.yaml (contrib)
  depending on the variant.
- The entrypoint is the otelcol binary; the default command loads the configuration from the installed config file.

## Start a opentelemetry-collector image

Basic usage (core distribution):

```bash
$ docker run -d --name dhi-opentelemetry-collector \
  -p 4317:4317 \   # OTLP gRPC
  -p 4318:4318 \   # OTLP HTTP
  -p 8888:8888 \   # internal Prometheus metrics
  -p 13133:13133 \ # health_check
  -v $(pwd)/config.yaml:/etc/otelcol/config.yaml:ro \
  dhi.io/opentelemetry-collector:<tag>
```

If you are using the contrib distribution (extra receivers/exporters/processors) mount your config at
/etc/otelcol-contrib/config.yaml and use the contrib image tag.

Passing a custom command or arguments:

```bash
$ docker run --rm -v $(pwd)/config.yaml:/etc/otelcol/config.yaml:ro \
  dhi.io/opentelemetry-collector:<tag> --config /etc/otelcol/config.yaml
```

### With Docker Compose (realistic setup)

This example runs the collector (contrib) receiving OTLP from instrumented apps and exporting traces to Jaeger and
metrics to Prometheus (via Prometheus exporter). Replace image, config and tags as needed.

```yaml
version: '3.8'
services:
  otel-collector:
    image: dhi.io/opentelemetry-collector:<tag>
    container_name: dhi-opentelemetry-collector
    ports:
      - '4317:4317'   # OTLP gRPC
      - '4318:4318'   # OTLP HTTP
      - '8888:8888'   # internal metrics
      - '13133:13133' # health
    volumes:
      - ./otel-config.yaml:/etc/otelcol-contrib/config.yaml:ro
    restart: unless-stopped

  jaeger:
    image: jaegertracing/all-in-one:1.42
    ports:
      - '6831:6831/udp'
      - '16686:16686'

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - '9090:9090'
```

## Environment variables and CLI options

The Collector is typically configured with a YAML file. The upstream image uses a default command that passes
`--config /etc/<dist>/config.yaml` to the binary. You can override this by supplying a different command or arguments to
docker run.

Common environment variables you may set for exporters and SDKs (standard OpenTelemetry env vars):

| Variable                    | Description                                        | Default | Required |
| --------------------------- | -------------------------------------------------- | ------- | -------- |
| OTEL_EXPORTER_OTLP_ENDPOINT | Endpoint for OTLP exporters (gRPC/HTTP)            | -       | No       |
| OTEL_EXPORTER_OTLP_HEADERS  | Headers passed to OTLP exporters (comma-separated) | -       | No       |
| OTEL_TRACES_SAMPLER         | SDK sampling strategy (on client side)             | -       | No       |

Collector-specific options are usually passed as CLI flags (for example `--config /etc/otelcol/config.yaml`) or embedded
in the YAML configuration.

## Example configuration snippets

A minimal otelcol receiver/exporter pipeline (YAML) for collecting OTLP and exporting to logging (useful for testing):

```yaml
receivers:
  otlp:
    protocols:
      grpc: {}
      http: {}

exporters:
  logging:
    loglevel: debug

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [logging]
```

A more realistic pipeline exporting metrics for Prometheus scraping and traces to Jaeger (contrib config may be required
for some exporters):

```yaml
receivers:
  otlp:
    protocols:
      grpc: { endpoint: "0.0.0.0:4317" }

processors:
  batch: {}

exporters:
  jaeger:
    endpoint: "jaeger:14250"
  prometheus:
    endpoint: "0.0.0.0:8889"

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [jaeger]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus]
```

Mount this config as /etc/otelcol-contrib/config.yaml when running the contrib image.

## Common opentelemetry-collector use cases

- Centralized collection gateway: Deploy the collector as a central gateway that receives OTLP from applications,
  applies processing (e.g., filters, batch, sampling), and forwards to observability backends.
- Sidecar/agent: Run a lightweight collector alongside services to aggregate local telemetry and send to a central
  collector.
- Testing and debugging: Use the logging exporter or file exporter to inspect telemetry during development.
- Metric scraping: Use the Prometheus exporter to provide a Prometheus scrape endpoint for collected metrics.

## Configuration and persistence

The collector is configuration-driven. Persist your YAML config externally (in a Git repo or configuration management
system) and mount it read-only into the container. There is no application-level persistent state by default; most
pipelines are stateless and forward telemetry to configured backends.

## Health, metrics and troubleshooting

- Health check endpoint: 13133 (extension `health_check`) — responds to readiness/liveness probes.
- Internal Prometheus metrics: 8888 (metrics about the collector itself)
- zPages (debugging): 55679 (if enabled)
- pprof: 1888 (if enabled)

Logs are emitted to stderr by the collector. Use `docker logs` or your container platform's logging driver to gather
logs.

## Security notes

- Avoid exposing receivers to the public internet without network-level protections and TLS. Configure authentication,
  TLS, and authorization where supported by receivers/exporters.
- Run the contrib image only if you need additional receivers/exporters. The core image is smaller and contains fewer
  third-party components.

## Non-hardened images vs. Docker Hardened Images

*Note: If there are no actual functional differences between the upstream and hardened image, this section can be
omitted.*

## Image variants

Docker Hardened Images come in different variants depending on their intended use. Image variants are identified by
their tag.

- Runtime variants are designed to run your application in production. These images are intended to be used either
  directly or as the FROM image in the final stage of a multi-stage build. These images typically:

  - Run as a nonroot user
  - Do not include a shell or a package manager
  - Contain only the minimal set of libraries needed to run the app

- Build-time variants typically include `dev` in the tag name and are intended for use in the first stage of a
  multi-stage Dockerfile. These images typically:

  - Run as the root user
  - Include a shell and package manager
  - Are used to build or compile applications

To view the image variants and get more information about them, select the Tags tab for this repository, and then select
a tag.

## Migrate to a Docker Hardened Image

To migrate your application to a Docker Hardened Image, you must update your Dockerfile. At minimum, you must update the
base image in your existing Dockerfile to a Docker Hardened Image. This and a few other common changes are listed in the
following table of migration notes.

| Item                                                    | Migration note                                                                                                                                                                                                                                                                                                               |
| :------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Base image                                              | Replace your base images in your Dockerfile with a Docker Hardened Image.                                                                                                                                                                                                                                                    |
| Package management                                      | Non-dev images, intended for runtime, don't contain package managers. Use package managers only in images with a `dev` tag.                                                                                                                                                                                                  |
| Non-root user                                           | By default, non-dev images, intended for runtime, run as the nonroot user. Ensure that necessary files and directories are accessible to the nonroot user.                                                                                                                                                                   |
| Multi-stage build                                       | Utilize images with a `dev` tag for build stages and non-dev images for runtime. To ensure that your final image is as minimal as possible, you should use a multi-stage build. All stages in your Dockerfile should use a hardened image. While intermediary stages will typically use images tagged as `dev`, your         |
| final runtime stage should use a non-dev image variant. |                                                                                                                                                                                                                                                                                                                              |
| TLS certificates                                        | Docker Hardened Images contain standard TLS certificates by default. There is no need to install TLS certificates.                                                                                                                                                                                                           |
| Ports                                                   | Non-dev hardened images run as a nonroot user by default. As a result, applications in these images can't bind to privileged ports (below 1024) when running in Kubernetes or in Docker Engine versions older than 20.10. To avoid issues, configure your application to listen on port 1025 or higher inside the container. |
| Entry point                                             | Docker Hardened Images may have different entry points than images such as Docker Official Images. Inspect entry points for Docker Hardened Images and update your Dockerfile if necessary.                                                                                                                                  |
| No shell                                                | By default, non-dev images, intended for runtime, don't contain a shell. Use dev images in build stages to run shell commands and then copy any necessary artifacts into the runtime stage. In addition, use Docker Debug to debug containers with no shell.                                                                 |

The following steps outline the general migration process.

1. Find hardened images for your app.

   A hardened image may have several variants. Inspect the image tags and find the image variant that meets your needs.

1. Update the base image in your Dockerfile.

   Update the base image in your application's Dockerfile to the hardened image you found in the previous step. For
   framework images, this is typically going to be an image tagged as `dev` because it has the tools needed to install
   packages and dependencies.

1. For multi-stage Dockerfiles, update the runtime image in your Dockerfile.

   To ensure that your final image is as minimal as possible, you should use a multi-stage build. All stages in your
   Dockerfile should use a hardened image. While intermediary stages will typically use images tagged as \`dev', your
   final runtime stage should use a non-dev image variant.

1. Install additional packages

   Docker Hardened Images contain minimal packages in order to reduce the potential attack surface. You may need to
   install additional packages in your Dockerfile. Inspect the image variants to identify which packages are already
   installed.

   Only images tagged as `dev` typically have package managers. You should use a multi-stage Dockerfile to install the
   packages. Install the packages in the build stage that uses a `dev` image. Then, if needed, copy any necessary
   artifacts to the runtime stage that uses a non-dev image.

   For Alpine-based images, you can use `apk` to install packages. For Debian-based images, you can use `apt-get` to
   install packages.

## Troubleshooting migration

The following are common issues that you may encounter during migration.

### General debugging

The hardened images intended for runtime don't contain a shell nor any tools for debugging. The recommended method for
debugging applications built with Docker Hardened Images is to use
[Docker Debug](https://docs.docker.com/reference/cli/docker/debug/) to attach to these containers. Docker Debug provides
a shell, common debugging tools, and lets you install other tools in an ephemeral, writable layer that only exists
during the debugging session.

### Permissions

By default image variants intended for runtime, run as the nonroot user. Ensure that necessary files and directories are
accessible to the nonroot user. You may need to copy files to different directories or change permissions so your
application running as the nonroot user can access them.

### Privileged ports

Non-dev hardened images run as a nonroot user by default. As a result, applications in these images can't bind to
privileged ports (below 1024) when running in Kubernetes or in Docker Engine versions older than 20.10. To avoid issues,
configure your application to listen on port 1025 or higher inside the container, even if you map it to a lower port on
the host. For example, `docker run -p 80:8080 my-image` will work because the port inside the container is 8080, and
`docker run -p 80:81 my-image` won't work because the port inside the container is 81.

### No shell

By default, image variants intended for runtime don't contain a shell. Use `dev` images in build stages to run shell
commands and then copy any necessary artifacts into the runtime stage. In addition, use Docker Debug to debug containers
with no shell.

### Entry point

Docker Hardened Images may have different entry points than images such as Docker Official Images. Use `docker inspect`
to inspect entry points for Docker Hardened Images and update your Dockerfile if necessary.
